@article{jin2021disease,
  title={What disease does this patient have? A large-scale open domain
  question answering dataset from medical exams},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and 
  Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={Applied Sciences},
  year={2021}
}

@inproceedings{pal2022medmcqa,
  title={MedMCQA: A large-scale multi-subject multi-choice dataset 
  for medical exam comprehension},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Conference on Health, Inference, and Learning},
  year={2022}
}

@inproceedings{jin2019pubmedqa,
  title={PubMedQA: A dataset for biomedical research question answering},
  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhiyong and 
  Cohen, William and Lu, Xinghua},
  booktitle={EMNLP},
  year={2019}
}

@article{abdin2024phi3,
  title={Phi-3 technical report: A highly capable language model 
  locally on your phone},
  author={Abdin, Marah and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@article{grattafiori2024llama,
  title={The Llama 3 herd of models},
  author={Grattafiori, Aaron and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{bedi2025systematic,
  title={A systematic review of large language model evaluations 
  in clinical medicine},
  author={Bedi, Sehej and others},
  journal={BMC Medical Informatics and Decision Making},
  year={2025}
}

@article{kim2025hallucination,
  title={Medical Hallucinations in Foundation Models and Their 
  Impact on Healthcare},
  author={Kim, Yubin and others},
  journal={arXiv preprint},
  year={2025}
}

@article{white2023prompt,
  title={A prompt pattern catalog to enhance prompt engineering 
  with ChatGPT},
  author={White, Jules and others},
  journal={arXiv preprint arXiv:2302.11382},
  year={2023}
}

@article{ngweta2024robustness,
  title={Towards LLMs Robustness to Changes in Prompt Format Styles},
  author={Ngweta, Lilian and others},
  journal={arXiv preprint},
  year={2024}
}

@article{lewis2020rag,
  title={Retrieval-augmented generation for 
  knowledge-intensive NLP tasks},
  author={Lewis, Patrick and others},
  journal={NeurIPS},
  year={2020}
}